import torch
import timm
from torchvision import transforms
from PIL import Image
import urllib.request
import time

# âœ… ëª¨ë¸ ë¡œë“œ
model_name = 'vit_base_patch16_clip_224.openai'
model = timm.create_model(model_name, pretrained=False)

# âœ… ì €ì¥ëœ weight ë¡œë“œ (CLIP pretrained)
ckpt_path = '/home/sogang/mnt/db_2/oh/ITPruner/vit_base_patch16_224.pth'
state_dict = torch.load(ckpt_path, map_location='cpu')

# ì¼ë¶€ í‚¤ mismatch ë°©ì§€
model.load_state_dict(state_dict, strict=False)
model.eval()

# âœ… í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ (ëœë¤ ë˜ëŠ” ì›¹ì—ì„œ ë¡œë“œ)
# ì˜ˆ: ê³ ì–‘ì´ ì´ë¯¸ì§€
image = Image.open("Cat03.jpg").convert("RGB")

# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (CLIP ê¸°ì¤€ 224x224)
transform = transforms.Compose([
    transforms.Resize(224, interpolation=transforms.InterpolationMode.BICUBIC),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=(0.48145466, 0.4578275, 0.40821073),  # OpenAI CLIP preprocessing mean
        std=(0.26862954, 0.26130258, 0.27577711)
    )
])

input_tensor = transform(image).unsqueeze(0)  # (1, 3, 224, 224)

# âœ… ì¶”ë¡ (: feature ì¶”ì¶œ) ì‹¤í–‰ + ì‹œê°„ ì¸¡ì •
with torch.no_grad():
    start_time = time.time()  # ì‹œì‘ ì‹œê°„
    output = model(input_tensor)
    end_time = time.time()    # ì¢…ë£Œ ì‹œê°„
    
# ImageNet í´ë˜ìŠ¤ ì¸ë±ìŠ¤ JSON ë‹¤ìš´ë¡œë“œ
# url = "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
# class_names = urllib.request.urlopen(url).read().decode('utf-8').splitlines()

top5_indices = torch.topk(output, 5).indices[0].tolist()

print("ğŸ” ëª¨ë¸ ì¶œë ¥:", output.shape)
# print(output)
# print("ğŸ”¥ ì˜ˆì¸¡ ê²°ê³¼ (Top-5 index):", top5_indices) # ì˜ˆì¸¡ ê²°ê³¼ (Top-5 index): [190, 180, 462, 144, 343]
# # ë§¤í•‘ ê²°ê³¼ ì¶œë ¥
# print("ğŸ” ì˜ˆì¸¡ í´ë˜ìŠ¤:")
# for idx in top5_indices:
#     print(f"{idx}: {class_names[idx]}")
    
# âœ… Inference ì‹œê°„ ì¶œë ¥
elapsed_time = end_time - start_time
print(f"â±ï¸ Inference Time: {elapsed_time:.4f}ì´ˆ")